// This would be nice once it stabilizes:
// https://github.com/rust-lang/rust/issues/44732
// #![feature(external_doc)]
// #![doc(include = "../README.md")]

//! This is a Rust crate which can take a [json schema (draft
//! 4)](http://json-schema.org/) and generate Rust types which are
//! serializable with [serde](https://serde.rs/). No checking such as
//! `min_value` are done but instead only the structure of the schema
//! is followed as closely as possible.
//!
//! As a schema could be arbitrarily complex this crate makes no
//! guarantee that it can generate good types or even any types at all
//! for a given schema but the crate does manage to bootstrap itself
//! which is kind of cool.
//!
//! ## Example
//!
//! Generated types for VS Codes [debug server protocol][]: <https://docs.rs/debugserver-types>
//!
//! [debug server protocol]:https://code.visualstudio.com/docs/extensions/example-debuggers
//!
//! ## Usage
//!
//! Rust code is generated by providing a [`Schema`](./struct.Schema.html) struct (which can be deserialized from JSON).
//!
//! A proc macro is available in [`schemafy`](https://docs.rs/schemafy) crate
//!
//! ```rust
//! extern crate serde;
//! extern crate schemafy_core;
//! extern crate serde_json;
//!
//! use serde::{Serialize, Deserialize};
//! use schemafy_lib::Expander;
//!
//! let json = std::fs::read_to_string("src/schema.json").expect("Read schema JSON file");
//!
//! let schema = serde_json::from_str(&json).unwrap();
//! let mut expander = Expander::new(
//!     Some("Schema"),
//!     "::schemafy_core::",
//!     &schema,
//! );
//!
//! let code = expander.expand(&schema);
//! ```

use std::collections::{BTreeMap, HashSet};
/// Types from the JSON Schema meta-schema (draft 4).
///
/// This module is itself generated from a JSON schema.
use std::{borrow::Cow, convert::TryFrom};

use inflector::Inflector;

use serde_json::Value;

use uriparse::{Fragment, URI};

pub use super::schema::{Schema, SimpleTypes};

pub use super::generator::{Generator, GeneratorBuilder};

use crate::instruction::schema::{Property, PropertyArray, VariantArray};
use proc_macro2::{Ident, Span, TokenStream};

fn replace_invalid_identifier_chars(s: &str) -> String {
    s.strip_prefix('$')
        .unwrap_or(s)
        .replace(|c: char| !c.is_alphanumeric() && c != '_', "_")
}

fn replace_numeric_start(s: &str) -> String {
    if s.chars().next().map(|c| c.is_numeric()).unwrap_or(false) {
        format!("_{}", s)
    } else {
        s.to_string()
    }
}

fn remove_excess_underscores(s: &str) -> String {
    let mut result = String::new();
    let mut char_iter = s.chars().peekable();

    while let Some(c) = char_iter.next() {
        let next_c = char_iter.peek();
        if c != '_' || !matches!(next_c, Some('_')) {
            result.push(c);
        }
    }

    result
}

pub fn str_to_ident(s: &str) -> syn::Ident {
    if s.is_empty() {
        return syn::Ident::new("empty_", Span::call_site());
    }

    if s.chars().all(|c| c == '_') {
        return syn::Ident::new("underscore_", Span::call_site());
    }

    let s = replace_invalid_identifier_chars(s);
    let s = replace_numeric_start(&s);
    let s = remove_excess_underscores(&s);

    if s.is_empty() {
        return syn::Ident::new("invalid_", Span::call_site());
    }

    let keywords = [
        "as", "break", "const", "continue", "crate", "else", "enum", "extern", "false", "fn",
        "for", "if", "impl", "in", "let", "loop", "match", "mod", "move", "mut", "pub", "ref",
        "return", "self", "static", "struct", "super", "trait", "true", "type", "unsafe", "use",
        "where", "while", "abstract", "become", "box", "do", "final", "macro", "override", "priv",
        "typeof", "unsized", "virtual", "yield", "async", "await", "try",
    ];
    if keywords.iter().any(|&keyword| keyword == s) {
        return syn::Ident::new(&format!("{}_", s), Span::call_site());
    }

    syn::Ident::new(&s, Span::call_site())
}

fn rename_keyword(prefix: &str, s: &str) -> Option<TokenStream> {
    let n = str_to_ident(s);

    if n == s {
        return None;
    }

    if prefix.is_empty() {
        Some(quote! {
            #[serde(rename = #s)]
            #n
        })
    } else {
        let prefix = syn::Ident::new(prefix, Span::call_site());
        Some(quote! {
            #[serde(rename = #s)]
            #prefix #n
        })
    }
}

fn field(s: &str) -> TokenStream {
    if let Some(t) = rename_keyword("pub", s) {
        return t;
    }
    let snake = s.to_snake_case();
    if snake == s && !snake.contains(|c: char| c == '$' || c == '#') {
        let field = syn::Ident::new(s, Span::call_site());
        return quote!( pub #field );
    }

    let field = if snake.is_empty() {
        syn::Ident::new("underscore", Span::call_site())
    } else {
        str_to_ident(&snake)
    };

    quote! {
        #[serde(rename = #s)]
        pub #field
    }
}

fn merge_option<T, F>(mut result: &mut Option<T>, r: &Option<T>, f: F)
where
    F: FnOnce(&mut T, &T),
    T: Clone,
{
    *result = match (&mut result, r) {
        (&mut &mut Some(ref mut result), &Some(ref r)) => return f(result, r),
        (&mut &mut None, &Some(ref r)) => Some(r.clone()),
        _ => return,
    };
}
/*
fn merge_all_of(result: &mut Schema, r: &Schema) {
    use std::collections::btree_map::Entry;

    for (k, v) in &r.properties {
        match result.properties.entry(k.clone()) {
            Entry::Vacant(entry) => {
                entry.insert(v.clone());
            }
            Entry::Occupied(mut entry) => merge_all_of(entry.get_mut(), v),
        }
    }

    if let Some(ref ref_) = r.ref_ {
        result.ref_ = Some(ref_.clone());
    }

    if let Some(ref description) = r.description {
        result.description = Some(description.clone());
    }

    merge_option(&mut result.required, &r.required, |required, r_required| {
        required.extend(r_required.iter().cloned());
    });

    result.type_.retain(|e| r.type_.contains(e));
}
*/
const LINE_LENGTH: usize = 100;
const INDENT_LENGTH: usize = 4;

fn make_doc_comment(mut comment: &str, remaining_line: usize) -> TokenStream {
    let mut out_comment = String::new();
    out_comment.push_str("/// ");
    let mut length = 4;
    while let Some(word) = comment.split(char::is_whitespace).next() {
        if comment.is_empty() {
            break;
        }
        comment = &comment[word.len()..];
        if length + word.len() >= remaining_line {
            out_comment.push_str("\n/// ");
            length = 4;
        }
        out_comment.push_str(word);
        length += word.len();
        let mut n = comment.chars();
        match n.next() {
            Some('\n') => {
                out_comment.push('\n');
                out_comment.push_str("/// ");
                length = 4;
            }
            Some(_) => {
                out_comment.push(' ');
                length += 1;
            }
            None => (),
        }
        comment = n.as_str();
    }
    if out_comment.ends_with(' ') {
        out_comment.pop();
    }
    out_comment.push('\n');
    out_comment.parse().unwrap()
}
pub fn expand_data_type(
    field_name: &TokenStream,
    data_type: &str,
    user_defined: bool,
) -> Option<TokenStream> {
    let type_name = data_type.parse::<TokenStream>().unwrap();
    match data_type {
        "u8" | "i8" | "u16" | "i16" | "u32" | "i32" | "u64" | "i64" | "u128" | "i128" => {
            Some(quote! {#type_name::from_le_bytes(#field_name)})
        }
        &_ => {
            Some(quote! {#type_name::unpack(&*#field_name).unwrap()})
            // if user_defined {
            //     Some(quote! {#type_name::unpack(#field_name)})
            // } else {
            //     Some(quote! {#type_name::try_from_primitive(#field_name)})
            // }
        }
    }
}
struct FieldExpander<'a, 'r: 'a> {
    default: bool,
    expander: &'a mut Expander<'r>,
}

impl<'a, 'r> FieldExpander<'a, 'r> {
    fn expand_fields(&mut self, type_name: &str, properties: &PropertyArray) -> Vec<TokenStream> {
        properties
            .iter()
            .map(|property| {
                let field_name = &property.name;
                self.expander.current_field.clone_from(field_name);
                let key = field(field_name);
                let field_type = self.expander.expand_type(
                    property.data_type.as_str(),
                    property.required,
                    property,
                );
                if !field_type.typ.starts_with("Option<") {
                    self.default = false;
                }
                //let typ = field_type.typ.parse::<TokenStream>().unwrap();
                let typ = property.data_type.parse::<TokenStream>().unwrap();
                let default = if field_type.default {
                    Some(quote! { #[serde(default)] })
                } else {
                    None
                };
                let attributes = if field_type.attributes.is_empty() {
                    None
                } else {
                    let attributes = field_type
                        .attributes
                        .iter()
                        .map(|attr| attr.parse::<TokenStream>().unwrap());
                    Some(quote! {
                        #[serde( #(#attributes),* )]
                    })
                };
                let comment = property
                    .description
                    .as_ref()
                    .map(|comment| make_doc_comment(comment, LINE_LENGTH - INDENT_LENGTH));
                quote! {
                    #comment
                    #default
                    #attributes
                    #key : #typ
                }
            })
            .collect()
    }
}

pub struct Expander<'r> {
    root_name: Option<&'r str>,
    schemafy_path: &'r str,
    root: &'r Schema,
    current_type: String,
    current_field: String,
    types: Vec<(String, TokenStream)>,
    definitions: BTreeMap<String, &'r Schema>,
}

struct FieldType {
    typ: String,
    attributes: Vec<String>,
    default: bool,
}

impl<S> From<S> for FieldType
where
    S: Into<String>,
{
    fn from(s: S) -> FieldType {
        FieldType {
            typ: s.into(),
            attributes: Vec::new(),
            default: false,
        }
    }
}

impl<'r> Expander<'r> {
    pub fn new(
        root_name: Option<&'r str>,
        schemafy_path: &'r str,
        root: &'r Schema,
    ) -> Expander<'r> {
        Expander {
            root_name,
            root,
            schemafy_path,
            current_field: "".into(),
            current_type: "".into(),
            types: Vec::new(),
            definitions: Default::default(),
        }
    }

    fn expand_type(&mut self, type_name: &str, required: bool, typ: &Property) -> FieldType {
        let saved_type = self.current_type.clone();
        //let mut result = self.expand_type_(typ);
        let mut result = FieldType::from(type_name.clone());
        self.current_type = saved_type;
        if type_name.to_pascal_case() == result.typ.to_pascal_case() {
            result.typ = format!("Box<{}>", result.typ)
        }
        if !required && !result.default {
            result.typ = format!("Option<{}>", result.typ);
            result
                .attributes
                .push("skip_serializing_if=\"Option::is_none\"".into());
        }
        result
    }

    pub fn expand_variants(&mut self, variants: &VariantArray) -> Vec<TokenStream> {
        variants
            .iter()
            .map(|variant| {
                let var_name = str_to_ident(variant.name.as_str());
                let var_token = quote! {
                    #var_name
                };
                let inner: Option<TokenStream> =
                    variant.inner_type.as_ref().and_then(|inner_type| {
                        let type_ident = str_to_ident(inner_type.as_str());
                        Some(quote! {
                            (#type_ident)
                        })
                    });
                let comment = variant
                    .description
                    .as_ref()
                    .map(|comment| make_doc_comment(comment, LINE_LENGTH - INDENT_LENGTH));
                quote! {
                    #comment
                    #var_token #inner
                }
            })
            .collect()
    }
    fn expand_definitions(&mut self, schema: &'r Schema) {
        for (name, def) in &schema.definitions {
            self.definitions.insert(name.clone(), def);
            let type_decl = self.expand_schema(name, def);
            let definition_tokens = match def.description {
                Some(ref comment) => {
                    let t = make_doc_comment(comment, LINE_LENGTH);
                    quote! {
                        #t
                        #type_decl
                    }
                }
                None => type_decl,
            };
            self.types.push((name.to_string(), definition_tokens));
        }
    }

    fn expand_schema(&mut self, original_name: &str, schema: &'r Schema) -> TokenStream {
        self.expand_definitions(schema);

        let pascal_case_name = replace_invalid_identifier_chars(&original_name.to_pascal_case());
        self.current_type.clone_from(&pascal_case_name);
        let name = syn::Ident::new(&pascal_case_name, Span::call_site());
        let serde_rename = if name == original_name {
            None
        } else {
            Some(quote! {
                #[serde(rename = #original_name)]
            })
        };
        let type_decl = if let Some(properties) = &schema.properties {
            let mut field_expander = FieldExpander {
                default: true,
                expander: self,
            };
            let fields = field_expander.expand_fields(original_name, properties);
            let unpack = self.expand_unpack_struct(&name, schema);
            quote! {
                #[derive(Clone, PartialEq, Debug, Deserialize, Serialize)]
                #serde_rename
                pub struct #name {
                    #(#fields),*
                }
                impl #name {
                    #unpack
                }
            }
        } else if let Some(variants) = &schema.variants {
            let unpack = self.expand_unpack_enum(&name, schema);
            let variants = self.expand_variants(variants);
            quote! {
                #[derive(Clone, PartialEq, Debug, Serialize, Deserialize)]
                #serde_rename
                pub enum #name {
                    #(#variants),*
                }
                impl #name {
                    #unpack
                }
            }
        } else {
            quote! {}
        };
        // let is_struct =
        //     !fields.is_empty() || schema.additional_properties == Some(Value::Bool(false));
        // let is_enum = schema.enum_.as_ref().map_or(false, |e| !e.is_empty());
        // let type_decl = if is_struct {
        //     if default {
        //         quote! {
        //             #[derive(Clone, PartialEq, Debug, Default, Deserialize, Serialize)]
        //             #serde_rename
        //             pub struct #name {
        //                 #(#fields),*
        //             }
        //         }
        //     } else {
        //         quote! {
        //             #[derive(Clone, PartialEq, Debug, Deserialize, Serialize)]
        //             #serde_rename
        //             pub struct #name {
        //                 #(#fields),*
        //             }
        //         }
        //     }
        // } else if is_enum {
        //     let mut optional = false;
        //     let mut repr_i64 = false;
        //     println!("{:?} {:?}", schema.enum_, schema.enum_names);
        //     let variants = if schema.enum_names.as_ref().map_or(false, |e| !e.is_empty()) {
        //         let values = schema.enum_.as_ref().map_or(&[][..], |v| v);
        //         let names = schema.enum_names.as_ref().map_or(&[][..], |v| v);
        //         if names.len() != values.len() {
        //             panic!(
        //                 "enumNames(length {}) and enum(length {}) have different length",
        //                 names.len(),
        //                 values.len()
        //             )
        //         }
        //         names
        //             .iter()
        //             .enumerate()
        //             .map(|(idx, name)| (&values[idx], name))
        //             .flat_map(|(value, name)| {
        //                 let pascal_case_variant = name.to_pascal_case();
        //                 let variant_name =
        //                     rename_keyword("", &pascal_case_variant).unwrap_or_else(|| {
        //                         let v = syn::Ident::new(&pascal_case_variant, Span::call_site());
        //                         quote!(#v)
        //                     });
        //                 match value {
        //                     Value::String(ref s) => Some(quote! {
        //                         #[serde(rename = #s)]
        //                         #variant_name
        //                     }),
        //                     Value::Number(ref n) => {
        //                         repr_i64 = true;
        //                         let num = syn::LitInt::new(&n.to_string(), Span::call_site());
        //                         Some(quote! {
        //                             #variant_name = #num
        //                         })
        //                     }
        //                     Value::Null => {
        //                         optional = true;
        //                         None
        //                     }
        //                     _ => panic!("Expected string,bool or number for enum got `{}`", value),
        //                 }
        //             })
        //             .collect::<Vec<_>>()
        //     } else {
        //         schema
        //             .enum_
        //             .as_ref()
        //             .map_or(&[][..], |v| v)
        //             .iter()
        //             .flat_map(|v| match *v {
        //                 Value::String(ref v) => {
        //                     let pascal_case_variant = v.to_pascal_case();
        //                     let variant_name = rename_keyword("", &pascal_case_variant)
        //                         .unwrap_or_else(|| {
        //                             let v =
        //                                 syn::Ident::new(&pascal_case_variant, Span::call_site());
        //                             quote!(#v)
        //                         });
        //                     Some(if pascal_case_variant == *v {
        //                         variant_name
        //                     } else {
        //                         quote! {
        //                             #[serde(rename = #v)]
        //                             #variant_name
        //                         }
        //                     })
        //                 }
        //                 Value::Null => {
        //                     optional = true;
        //                     None
        //                 }
        //                 _ => panic!("Expected string for enum got `{}`", v),
        //             })
        //             .collect::<Vec<_>>()
        //     };
        //     if optional {
        //         let enum_name = syn::Ident::new(&format!("{}_", name), Span::call_site());
        //         if repr_i64 {
        //             quote! {
        //                 pub type #name = Option<#enum_name>;
        //                 #[derive(Clone, PartialEq, Debug, Serialize_repr, Deserialize_repr)]
        //                 #serde_rename
        //                 #[repr(i64)]
        //                 pub enum #enum_name {
        //                     #(#variants),*
        //                 }
        //             }
        //         } else {
        //             quote! {
        //                 pub type #name = Option<#enum_name>;
        //                 #[derive(Clone, PartialEq, Debug, Deserialize, Serialize)]
        //                 #serde_rename
        //                 pub enum #enum_name {
        //                     #(#variants),*
        //                 }
        //             }
        //         }
        //     } else if repr_i64 {
        //         quote! {
        //             #[derive(Clone, PartialEq, Debug, Serialize_repr, Deserialize_repr)]
        //             #serde_rename
        //             #[repr(i64)]
        //             pub enum #name {
        //                 #(#variants),*
        //             }
        //         }
        //     } else {
        //         quote! {
        //             #[derive(Clone, PartialEq, Debug, Deserialize, Serialize)]
        //             #serde_rename
        //             pub enum #name {
        //                 #(#variants),*
        //             }
        //         }
        //     }
        // } else {
        //     let typ = self
        //         .expand_type("", true, schema)
        //         .typ
        //         .parse::<TokenStream>()
        //         .unwrap();
        //     // Skip self-referential types, e.g. `struct Schema = Schema`
        //     if name == typ.to_string() {
        //         return TokenStream::new();
        //     }
        //     return quote! {
        //         pub type #name = #typ;
        //     };
        // };
        type_decl
    }
    pub fn expand_unpack_struct(&mut self, name: &Ident, schema: &Schema) -> TokenStream {
        let struct_size = schema.properties.as_ref().and_then(|properties| {
            let mut total_size = 0_usize;
            for property in properties {
                total_size = total_size + property.size()
            }
            Some(total_size)
        });
        let size_stream = struct_size.and_then(|val| Some(quote!(#val)));
        if let Some(val) = struct_size {
            let mut offset = 0usize;
            let mut ref_names: Vec<TokenStream> = Vec::default();
            let mut lengths: Vec<usize> = Vec::default();
            let mut properties: Vec<TokenStream> = Vec::default();
            for property in schema.properties.as_ref().unwrap() {
                let field_name = property.name.parse::<TokenStream>().unwrap();
                ref_names.push(quote! {&#field_name});
                lengths.push(property.size());
                //Expand struct field's data type.
                //Use unpack for user defined type other use try_from_primitive
                let field_value = expand_data_type(
                    &field_name,
                    property.data_type.as_str(),
                    self.definitions.contains_key(&property.name),
                );
                if field_value.is_some() {
                    properties.push(quote! {
                        #field_name: #field_value
                    });
                }
            }
            if size_stream.is_some() {
                quote! {
                    pub fn unpack(input: &[u8; #size_stream]) -> Option<Self> {
                        let (#(#ref_names),*) = array_refs![input, #(#lengths),*];
                        Some(#name {
                            #(#properties),*
                        })
                    }
                }
            } else {
                quote! {
                    pub fn unpack(input: &[u8]) -> Option<Self> {
                        let (#(#ref_names),*) = array_refs![input, #(#lengths),*];
                        Some(#name {
                            #(#properties),*
                        })
                    }
                }
            }
        } else {
            quote! {
                pub fn unpack(input: &[u8]) -> Option<Self> {
                    None
                }
            }
        }
    }
    pub fn expand_unpack_enum(&mut self, name: &Ident, schema: &Schema) -> TokenStream {
        let variants: Vec<TokenStream> = schema
            .variants
            .as_ref()
            .unwrap()
            .iter()
            .map(|variant| {
                let var_token = variant.name.parse::<TokenStream>().unwrap();
                let var_tag = variant.variant_tag;
                match &variant.inner_type {
                    Some(inner_type) => {
                        let inner_schema = self.definitions.get(inner_type);
                        println!("{:?}", inner_schema);
                        //let inner = inner_type.parse::<TokenStream>().unwrap();
                        match variant.get_size() {
                            None => {
                                let field_name = quote! { data_array };
                                let inner_value =
                                    expand_data_type(&field_name, inner_type.as_str(), true);
                                quote! {
                                    #var_tag => {
                                        //let data_array = array_ref![data, 0, 34];
                                        Some(#name::#var_token(#inner_value))
                                    }
                                }
                            }
                            Some(size) => {
                                let field_name = quote! { field_slice };
                                let inner_value =
                                    expand_data_type(&field_name, inner_type.as_str(), true);
                                quote! {
                                    #var_tag => {
                                        let (&field_slice, remain) = array_refs![data, #size; ..;];
                                        Some(#name::#var_token(#inner_value))
                                    }
                                }
                            }
                        }
                    }
                    None => {
                        quote! {
                            #var_tag => Some(#name::#var_token)
                        }
                    }
                }
            })
            .collect();
        let tag_len = schema.variant_tag_length.unwrap_or(1usize);
        let tag_val = match tag_len {
            1 => quote! {let tag_val = u8::from_le_bytes(tag_slice) as u32;},
            2 => quote! {let tag_val = u16::from_le_bytes(tag_slice) as u32;},
            _ => quote! {let tag_val = u32::from_le_bytes(tag_slice) as u32;},
            //_ => quote! {let tag_val = u64::from_le_bytes(tag_slice);},
        };
        let separation = match schema.offset {
            None => {
                quote! {
                    let (&tag_slice, data) = array_refs![input, #tag_len; ..;];
                }
            }
            Some(offset) => {
                quote! {
                    let (&[offset], &tag_slice, data) = array_refs![input, #offset, #tag_len; ..;];
                }
            }
        };
        quote! {
            pub fn unpack(input: &[u8]) -> Option<Self> {
                #separation
                #tag_val
                match tag_val {
                    #(#variants),*
                }
            }
        }
    }
    pub fn expand(&mut self, schema: &'r Schema) -> TokenStream {
        match self.root_name {
            Some(name) => {
                let schema = self.expand_schema(name, schema);
                self.types.push((name.to_string(), schema));
            }
            None => self.expand_definitions(schema),
        }

        let types = self.types.iter().map(|t| &t.1);
        //Includes used libraries
        quote! {
            use bytemuck::cast;
            use serde::{Deserialize, Serialize};
            use std::convert::TryInto;

            use arrayref::{array_ref, array_refs};
            use num_enum::{IntoPrimitive, TryFromPrimitive};
            use std::num::*;
            #( #types )*
        }
    }

    pub fn expand_root(&mut self) -> TokenStream {
        self.expand(self.root)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_expander_type_ref() {
        let json = std::fs::read_to_string("src/schema.json").expect("Read schema JSON file");
        let schema = serde_json::from_str(&json).unwrap_or_else(|err| panic!("{}", err));
        let expander = Expander::new(Some("SchemaName"), "::schemafy_core::", &schema);

        assert_eq!(expander.type_ref("normalField"), "NormalField");
        assert_eq!(expander.type_ref("#"), "SchemaName");
        assert_eq!(expander.type_ref(""), "SchemaName");
        assert_eq!(expander.type_ref("1"), "_1");
        assert_eq!(
            expander.type_ref("http://example.com/schema.json#"),
            "SchemaName"
        );
        assert_eq!(
            expander.type_ref("http://example.com/normalField#withFragment"),
            "WithFragment"
        );
        assert_eq!(
            expander.type_ref("http://example.com/normalField#withFragment/and/path"),
            "Path"
        );
        assert_eq!(
            expander.type_ref("http://example.com/normalField?with&params#andFragment/and/path"),
            "Path"
        );
        assert_eq!(expander.type_ref("#/only/Fragment"), "Fragment");

        // Invalid cases, just to verify the behavior
        assert_eq!(expander.type_ref("ref"), "Ref");
        assert_eq!(expander.type_ref("_"), "");
        assert_eq!(expander.type_ref("thieves' tools"), "ThievesTools");
        assert_eq!(
            expander.type_ref("http://example.com/normalField?with&params=1"),
            "NormalFieldWithParams1"
        );
    }

    #[test]
    fn embedded_type_names() {
        use std::collections::HashSet;

        let json = std::fs::read_to_string("tests/multiple-property-types.json")
            .expect("Read schema JSON file");
        let schema = serde_json::from_str(&json).unwrap();
        let mut expander = Expander::new(Some("Root"), "UNUSED", &schema);
        expander.expand(&schema);

        // check that the type names for embedded objects only include their
        // ancestors' type names, and not names from unrelated fields
        let types = expander
            .types
            .iter()
            .map(|v| v.0.as_str())
            .collect::<HashSet<&str>>();
        assert!(types.contains("RootItemAC"));
        assert!(types.contains("RootKM"));
        assert!(types.contains("RootTV"));
    }
}
